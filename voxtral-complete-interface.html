<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voxtral Voice AI - Complete Interface</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
            text-align: center;
        }
        
        .status-panel {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            backdrop-filter: blur(10px);
        }
        
        #connectionStatus {
            position: fixed;
            top: 20px;
            right: 20px;
            padding: 10px 20px;
            border-radius: 25px;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .connected { background: #4CAF50; color: white; }
        .connecting { background: #FF9800; color: black; }
        .disconnected { background: #F44336; color: white; }
        .error { background: #F44336; color: white; animation: pulse 1s infinite; }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        
        .controls {
            margin: 30px 0;
        }
        
        button {
            background: rgba(255,255,255,0.2);
            border: 2px solid white;
            color: white;
            padding: 15px 30px;
            margin: 10px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 16px;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        button:hover {
            background: rgba(255,255,255,0.3);
            transform: translateY(-2px);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        
        .start-btn { border-color: #4CAF50; }
        .stop-btn { border-color: #F44336; }
        
        #transcriptionOutput {
            background: rgba(0,0,0,0.3);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            min-height: 100px;
            text-align: left;
            font-family: 'Courier New', monospace;
            max-height: 300px;
            overflow-y: auto;
        }
        
        .welcome-message {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voxtral Voice AI Conversation</h1>
        
        <div id="connectionStatus" class="disconnected">
            üîÑ Initializing...
        </div>
        
        <div class="welcome-message" id="welcomeMessage">
            <h2>Welcome to Voxtral Voice AI!</h2>
            <p><strong>Click "Start Conversation" to begin</strong></p>
            <p>This will enable your microphone and audio playback.</p>
            <small>‚ö° Ultra-low latency voice conversation powered by Mistral Voxtral Mini 3B</small>
        </div>
        
        <div class="controls">
            <button id="startButton" class="start-btn" onclick="startConversation()">
                üé§ Start Conversation
            </button>
            <button id="stopButton" class="stop-btn" onclick="stopConversation()" disabled>
                ‚èπÔ∏è Stop Conversation
            </button>
        </div>
        
        <div class="status-panel">
            <h3>Conversation Status</h3>
            <div id="conversationStatus">Ready to start</div>
        </div>
        
        <div id="transcriptionOutput">
            <p><em>Conversation transcript will appear here...</em></p>
        </div>
    </div>

    <script>
        // Global variables
        let voxtralWS = null;
        let audioManager = null;
        let isConversationActive = false;
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', async () => {
            console.log('[Voxtral VAD] Initializing Voxtral Voice AI System...');
            
            // Initialize audio manager
            audioManager = new VoxtralAudioManager();
            
            // Initialize WebSocket connection
            initializeWebSocket();
            
            console.log('[Voxtral VAD] System ready - click Start Conversation to begin');
        });
        
        // Audio Manager Class with Chrome Autoplay Policy Support
        class VoxtralAudioManager {
            constructor() {
                this.audioContext = null;
                this.mediaStream = null;
                this.isInitialized = false;
                this.SAMPLE_RATE = 16000;
            }
            
            async initializeAudio() {
                try {
                    console.log('[Voxtral Audio] Initializing audio with user gesture...');
                    
                    // Request microphone access
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: this.SAMPLE_RATE,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });
                    
                    // Create audio context
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: this.SAMPLE_RATE
                    });
                    
                    // Resume context if suspended (Chrome autoplay policy)
                    if (this.audioContext.state === 'suspended') {
                        console.log('[Voxtral Audio] Resuming suspended audio context...');
                        await this.audioContext.resume();
                    }
                    
                    console.log(`[Voxtral Audio] ‚úÖ Audio initialized - Sample Rate: ${this.audioContext.sampleRate}Hz, State: ${this.audioContext.state}`);
                    this.isInitialized = true;
                    return true;
                    
                } catch (error) {
                    console.error('[Voxtral Audio] Audio initialization failed:', error);
                    return false;
                }
            }
            
            async playAudioResponse(base64Audio) {
                try {
                    if (!this.isInitialized) {
                        console.warn('[Voxtral Audio] Audio not initialized, cannot play response');
                        return;
                    }
                    
                    // Convert base64 to audio buffer
                    const audioData = atob(base64Audio);
                    const audioBuffer = new ArrayBuffer(audioData.length);
                    const uint8Array = new Uint8Array(audioBuffer);
                    
                    for (let i = 0; i < audioData.length; i++) {
                        uint8Array[i] = audioData.charCodeAt(i);
                    }
                    
                    // Decode and play
                    const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);
                    const source = this.audioContext.createBufferSource();
                    source.buffer = decodedAudio;
                    source.connect(this.audioContext.destination);
                    source.start();
                    
                    console.log(`[Voxtral Audio] Playing response - ${decodedAudio.duration.toFixed(2)}s`);
                    
                } catch (error) {
                    console.error('[Voxtral Audio] Playback failed:', error);
                }
            }
        }
        
        // WebSocket initialization with RunPod support
        function initializeWebSocket() {
            // RunPod WebSocket URL format: wss://POD_ID-PORT.proxy.runpod.net/ws
            const wsUrl = 'wss://dnsh4pxuild7cv-8000.proxy.runpod.net/ws';
            
            console.log('[Voxtral VAD] Connecting to:', wsUrl);
            updateConnectionStatus('connecting');
            
            try {
                voxtralWS = new WebSocket(wsUrl);
                
                voxtralWS.onopen = function(event) {
                    console.log('[Voxtral VAD] ‚úÖ Connected to Voxtral Voice AI!');
                    updateConnectionStatus('connected');
                    document.getElementById('conversationStatus').textContent = 'Connected - Ready to start conversation';
                };
                
                voxtralWS.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    handleVoxtralMessage(data);
                };
                
                voxtralWS.onclose = function(event) {
                    console.log(`[Voxtral VAD] Connection closed: ${event.code}`);
                    updateConnectionStatus('disconnected');
                    
                    if (event.code !== 1000) {
                        // Auto-reconnect
                        setTimeout(initializeWebSocket, 5000);
                    }
                };
                
                voxtralWS.onerror = function(error) {
                    console.error('[Voxtral VAD] WebSocket error:', error);
                    updateConnectionStatus('error');
                };
                
            } catch (error) {
                console.error('[Voxtral VAD] WebSocket creation failed:', error);
                updateConnectionStatus('error');
            }
        }
        
        // Start conversation function with Chrome autoplay policy handling
        async function startConversation() {
            console.log('[Voxtral VAD] Starting conversation...');
            
            try {
                // Initialize audio (this handles Chrome autoplay policy)
                const audioReady = await audioManager.initializeAudio();
                
                if (!audioReady) {
                    alert('Failed to initialize audio. Please check microphone permissions and try again.');
                    return;
                }
                
                // Update UI
                document.getElementById('startButton').disabled = true;
                document.getElementById('stopButton').disabled = false;
                document.getElementById('conversationStatus').textContent = 'üé§ Listening...';
                document.getElementById('welcomeMessage').style.display = 'none';
                
                isConversationActive = true;
                
                // Send start message to backend
                if (voxtralWS && voxtralWS.readyState === WebSocket.OPEN) {
                    voxtralWS.send(JSON.stringify({
                        type: 'start_conversation',
                        config: {
                            language: 'en',
                            voice: 'hf_alpha',
                            streaming: true,
                            sample_rate: 16000
                        }
                    }));
                }
                
                console.log('[Voxtral VAD] ‚úÖ Conversation started successfully!');
                
            } catch (error) {
                console.error('[Voxtral VAD] Failed to start conversation:', error);
                alert('Failed to start conversation: ' + error.message);
                
                // Reset button states
                document.getElementById('startButton').disabled = false;
                document.getElementById('stopButton').disabled = true;
            }
        }
        
        // Stop conversation function
        function stopConversation() {
            console.log('[Voxtral VAD] Stopping conversation...');
            
            // Update UI
            document.getElementById('startButton').disabled = false;
            document.getElementById('stopButton').disabled = true;
            document.getElementById('conversationStatus').textContent = 'Conversation stopped';
            
            isConversationActive = false;
            
            // Send stop message to backend
            if (voxtralWS && voxtralWS.readyState === WebSocket.OPEN) {
                voxtralWS.send(JSON.stringify({
                    type: 'stop_conversation'
                }));
            }
            
            // Stop audio stream
            if (audioManager.mediaStream) {
                audioManager.mediaStream.getTracks().forEach(track => track.stop());
            }
        }
        
        // Handle messages from backend
        function handleVoxtralMessage(data) {
            console.log(`[Voxtral VAD] Received: ${data.type}`);
            
            switch (data.type) {
                case 'connection':
                    console.log('[Voxtral VAD] Connection confirmed');
                    break;
                    
                case 'streaming_words':
                    updateTranscription(`AI: ${data.text}`, 'assistant');
                    break;
                    
                case 'audio_response':
                    // Play audio response
                    if (data.audio_data) {
                        audioManager.playAudioResponse(data.audio_data);
                    }
                    break;
                    
                case 'transcription':
                    updateTranscription(`You: ${data.text}`, 'user');
                    break;
                    
                default:
                    console.log('[Voxtral VAD] Unknown message type:', data.type);
            }
        }
        
        // Update connection status
        function updateConnectionStatus(status) {
            const statusElement = document.getElementById('connectionStatus');
            statusElement.className = status;
            
            const statusText = {
                'connected': 'üü¢ Connected',
                'connecting': 'üü° Connecting...',
                'disconnected': 'üî¥ Disconnected',
                'error': '‚ö†Ô∏è Connection Error'
            };
            
            statusElement.textContent = statusText[status] || `Status: ${status}`;
        }
        
        // Update transcription
        function updateTranscription(text, role) {
            const output = document.getElementById('transcriptionOutput');
            const timestamp = new Date().toLocaleTimeString();
            const roleIcon = role === 'user' ? 'üó£Ô∏è' : 'ü§ñ';
            
            output.innerHTML += `<p><strong>[${timestamp}] ${roleIcon} ${text}</strong></p>`;
            output.scrollTop = output.scrollHeight;
        }
    </script>
</body>
</html>